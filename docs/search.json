[
  {
    "objectID": "posts/2023-05-09_01-golem-of-prague/index.html",
    "href": "posts/2023-05-09_01-golem-of-prague/index.html",
    "title": "01 Golem of Prague Chapter",
    "section": "",
    "text": "Listening"
  },
  {
    "objectID": "posts/2023-05-09_01-golem-of-prague/index.html#hypotheses-models-statistics",
    "href": "posts/2023-05-09_01-golem-of-prague/index.html#hypotheses-models-statistics",
    "title": "01 Golem of Prague Chapter",
    "section": "Hypotheses != Models != Statistics",
    "text": "Hypotheses != Models != Statistics\n\n\n\n\nflowchart LR\n  H0(\"H0&lt;br&gt;Evolution is Neutral\") &lt;--&gt; P0A[\"Process&lt;br&gt;Neutral Equilibrium\"] \n  H0 &lt;--&gt; P0B[\"Process&lt;br&gt;Neutral Non-Equilibrium\"]\n  H1(\"H1&lt;br&gt;Selection Matters\") &lt;--&gt; P1A[\"Process&lt;br&gt;Constant Selection\"]\n  H1 &lt;--&gt; P1B[\"Process&lt;br&gt;Fluctuating Selection\"]\n  \n  P0A &lt;--&gt; MII([\"Model2&lt;br&gt;Power Law\"])\n  P1B &lt;--&gt; MII\n  P1A &lt;--&gt; MIII([\"Model3&lt;br&gt;'something different'\"])\n  P0B &lt;--&gt; MI([\"Model1&lt;br&gt;another thing\"])\n\n\n\n\n\nRejecting Model 1 does not result in a unique identification of a process, or even a hypothesis."
  },
  {
    "objectID": "posts/2023-05-09_00-setup/index.html",
    "href": "posts/2023-05-09_00-setup/index.html",
    "title": "Setup",
    "section": "",
    "text": "I’ve set up the blog using the default quarto blog template in RStudio, also initializing a git repo and renv.\n\nrenv::install(c(\"tidyverse\", \"brms\"))\nrenv::install(c(\"coda\", \"mvtnorm\", \"dagitty\"))\n\nThe preface wants to install the book package with devtooks::install_github(), but I’m pretty sure that’s been superseded with remotes::install_github(), and renv::install().\n\ninstall.packages(\"cmdstanr\", repos = c(\"https://mc-stan.org/r-packages/\", getOption(\"repos\")))\nrenv::install(\"rmcelreath/rethinking\")"
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html",
    "title": "Garden of Forking paths part 2",
    "section": "",
    "text": "Listening\nrenv::install(\"khroma\")\nlibrary(tidyverse)\nlibrary(khroma)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(here)\nsource(here(\"_defaults.R\"))"
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html#a-nicer-table-version.",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html#a-nicer-table-version.",
    "title": "Garden of Forking paths part 2",
    "section": "A nicer table version.",
    "text": "A nicer table version.\nI’d like to re-represent the Bayesian Update in a nicer GT table. Some options are\n\nPlotting extensions from {gtExtras}\nEmojis\n\n\nrenv::install(\"gtExtras\")\nrenv::install(\"svglite\")\nrenv::install(\"emoji\")\n\n\nlibrary(gtExtras)\nlibrary(emoji)\n\nFirst, trying the “win/losses” column plot from {gtExtra} to illustrate the blue vs white marbles.\n\ntibble(\n  blue_marbs = 0:4,\n  white_marbs = 4 - blue_marbs\n) |&gt; \n  rowwise() |&gt; \n  mutate(\n    marbles = list(c(rep(1, blue_marbs), \n                     rep(0, white_marbs)))\n  ) -&gt; \n  marbles_wl\n\nThe cell background will have to be off-white for the white ticks to show\n\nmarbles_wl |&gt; \n  gt() |&gt; \n  gt_plt_winloss(marbles, palette = c(\"blue\", \"white\", \"grey\")) |&gt; \n  tab_style(style = cell_fill(color = \"antiquewhite\"), \n            locations = cells_body())\n\n\n\n\n\n\n  \n    \n    \n      blue_marbs\n      white_marbs\n      marbles\n    \n  \n  \n    0\n4\n          \n    1\n3\n          \n    2\n2\n          \n    3\n1\n          \n    4\n0\n          \n  \n  \n  \n\nTable 1:  Representing marble compositions with ‘win-loss’ plots \n\n\n\nI’m not overwhelmed by the result. I’ll try emojis instead.\n\n## Getting the blue circle emoji\nblue_marb &lt;- emojis |&gt; \n  filter(str_detect(name, \"blue\"), \n         str_detect(name, \"circle\")) |&gt; \n  pull(emoji)\n\nblue_marb\n\n[1] \"🔵\"\n\n\n\n## Getting the white circle emoji\nwhite_marb &lt;- emojis |&gt; \n  filter(str_detect(name, \"white\"), \n         str_detect(name, \"circle\")) |&gt; \n  pull(emoji)\n\nwhite_marb\n\n[1] \"⚪\"\n\n\n\ntibble(\n  blue_marbs = 0:4,\n  white_marbs = 4 - blue_marbs\n) |&gt; \n  rowwise() |&gt; \n  mutate(\n    marbles = list(c(rep(blue_marb, blue_marbs), \n                     rep(white_marb, white_marbs)))\n  ) -&gt; \n  marbles_emoji\n\n\nmarbles_emoji |&gt; \n  gt()\n\n\n\n\n\n\n  \n    \n    \n      blue_marbs\n      white_marbs\n      marbles\n    \n  \n  \n    0\n4\n⚪, ⚪, ⚪, ⚪\n    1\n3\n🔵, ⚪, ⚪, ⚪\n    2\n2\n🔵, 🔵, ⚪, ⚪\n    3\n1\n🔵, 🔵, 🔵, ⚪\n    4\n0\n🔵, 🔵, 🔵, 🔵\n  \n  \n  \n\nTable 2:  Representing marble compositions with emoji \n\n\n\nYes, this is it.\n\nRerunning the sampling\nI’ll re-run the sampling from the previous post.\n\nsampling_df &lt;- function(marbles, \n                        n = 1000, \n                        size = 3, \n                        pattern = c(blue_marb, white_marb, blue_marb)){\n  sampling_tibble &lt;- tibble(samp = 1:n)   \n  sampling_tibble |&gt; \n    mutate(\n      chosen = map(samp, \n                   ~sample(marbles, \n                           size = 3, \n                           replace = T)),\n      match = map_lgl(chosen, \n                      ~all(.x == pattern))                 \n    ) |&gt; \n    summarise(prop_match = mean(match))-&gt;                         \n    sampling_tibble\n  return(sampling_tibble)\n}\n\n\nmarbles_emoji |&gt; \n ungroup() |&gt; \n  mutate(\n    prob = map(marbles, ~sampling_df(.x, n = 10000))\n  ) |&gt; \n  unnest(prob) |&gt; \n  mutate(norm_probs = prop_match/sum(prop_match))-&gt;\n  marble_probs\n\nI want to label the column of probabilities with the key sequence.\n\nkey_seq &lt;- str_glue(\"{blue_marb}, {white_marb}, {blue_marb}\")\n\ngtExtras::gt_plt_bar_pct() will plot a bar chart within the table.\n\nmarble_probs |&gt; \n  select(marbles, norm_probs) |&gt; \n  mutate(norm_probs = norm_probs * 100) |&gt; \n  gt() |&gt; \n  cols_label(\n    norm_probs = str_glue(\"p(marbles | {key_seq})\")\n  ) |&gt; \n  gt_plt_bar_pct(norm_probs, \n                 scaled = T, \n                 fill = \"steelblue\")\n\n\n\n\n\n\n  \n    \n    \n      marbles\n      p(marbles | 🔵, ⚪, 🔵)\n    \n  \n  \n    ⚪, ⚪, ⚪, ⚪\n\n    🔵, ⚪, ⚪, ⚪\n\n    🔵, 🔵, ⚪, ⚪\n\n    🔵, 🔵, 🔵, ⚪\n\n    🔵, 🔵, 🔵, 🔵\n\n  \n  \n  \n\nTable 3:  Probability of each marble composition given (🔵, ⚪️, 🔵) samples\nwith replacement. \n\n\n\nThere we go!\n\n\nWith the Bayesian Update\n\nmarble_probs |&gt; \n  mutate(new_prob = blue_marbs/sum(blue_marbs),\n         multiplied = norm_probs * new_prob,\n         norm_new = multiplied/sum(multiplied)) |&gt; \n  select(marbles, norm_probs, norm_new) |&gt; \n  mutate(norm_probs = norm_probs * 100,\n         norm_new = norm_new * 100) |&gt; \n  gt() |&gt; \n  cols_label(\n    norm_probs = str_glue(\"p(marbles | {key_seq})\"),\n    norm_new = str_glue(\"after {blue_marb}\")\n  ) |&gt; \n  gt_plt_bar_pct(norm_probs, \n                 scaled = T, \n                 fill = \"steelblue\") |&gt; \n  gt_plt_bar_pct(norm_new, \n                 scaled = T, \n                 fill = \"steelblue\") |&gt; \n  ## Necessary to get the percent bars\n  ## to be equal length.\n  cols_width(2 ~ px(200),\n             3 ~ px(200))\n\n\n\n\n\n\n  \n    \n    \n    \n  \n  \n    \n    \n      marbles\n      p(marbles | 🔵, ⚪, 🔵)\n      after 🔵\n    \n  \n  \n    ⚪, ⚪, ⚪, ⚪\n\n\n    🔵, ⚪, ⚪, ⚪\n\n\n    🔵, 🔵, ⚪, ⚪\n\n\n    🔵, 🔵, 🔵, ⚪\n\n\n    🔵, 🔵, 🔵, 🔵\n\n\n  \n  \n  \n\nTable 4:  Probability of each marble composition given an additional (🔵)\nsample"
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html#bayesian-updating",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html#bayesian-updating",
    "title": "Garden of Forking paths part 2",
    "section": "Bayesian Updating",
    "text": "Bayesian Updating\nI’ll try to illustrate Baysian updating with an animated plotly plot.\n\nrenv::install(\"plotly\")\nrenv::install(\"slider\")\n\n\nlibrary(plotly)\nlibrary(slider)\n\nI know enough to know that the distribution that’s being updated is the beta. (Apparently is the binomial. Still a but lost on their distinction!) So I’ll get the density for each update.\n\nplot(\n  seq(0,1, length =100),\n  dbeta(seq(0,1, length =100), 1, 1),\n  type = 'l'\n)\n\n\n\n\n\nwater_land_sequence &lt;- c(\"W\", \"L\", \"W\", \"W\", \"L\", \"W\", \"L\", \"W\")\n\nI’ll use slider::slide() to generate a data frame of sample updates. I’ll need a function that takes a sequence of W and L and converts them into counts.\n\nw_l_count &lt;- function(x){\n  tibble(\n    water = sum(x == \"W\"),\n    land = sum(x == \"L\")\n  )\n}\n\n\nslide(water_land_sequence, \n      .f = w_l_count, \n      .before = Inf,\n      .after = 0) |&gt; \n  bind_rows() |&gt; \n  mutate(seq = row_number()) |&gt; \n  bind_rows(\n    tibble(\n      water = 0,\n      land = 0, \n      seq = 0\n    )\n  ) |&gt; \n  arrange(seq) -&gt;\n  sequence_counts\n\n\nsequence_counts |&gt; \n  gt()\n\n\n\n\n\n\n  \n    \n    \n      water\n      land\n      seq\n    \n  \n  \n    0\n0\n0\n    1\n0\n1\n    1\n1\n2\n    2\n1\n3\n    3\n1\n4\n    3\n2\n5\n    4\n2\n6\n    4\n3\n7\n    5\n3\n8\n  \n  \n  \n\nTable 5:  Table of water, land count updates \n\n\n\nNow to get the densities.\n\nsequence_counts |&gt; \n  rowwise() |&gt; \n  mutate(\n    density = map2(\n      water, land, ~tibble(prop = seq(0.0001, 0.9999, length = 100),\n                           density_unstd = dbinom(water, size = water + land, prob = prop),\n                           density = density_unstd/sum(density_unstd)\n                           )\n    )\n  ) |&gt; \n  unnest(density)-&gt;\n  density_updates\n\n\ndensity_updates |&gt; \n  ggplot(aes(prop, density))+\n    geom_line(aes(group = seq, color = seq))\n\n\n\n\nFigure 1: beta distribution updates\n\n\n\n\nGood first step.\nI had to turn to the plotly book to get the animated lines correct https://plotly-r.com/animating-views.html.\n\nsequence_counts |&gt; \n  mutate(\n    annotation = str_glue(\"W:{water}, L:{land}\")\n  ) -&gt; \n  wl_annotate\n\n\ndensity_updates |&gt; \n  plot_ly() |&gt; \n  add_lines(\n    x = ~prop,\n    y = ~density,\n    frame = ~seq,\n    line = list(simplify = F, width = 3)\n  ) |&gt; \n  add_text(\n    data = wl_annotate,\n    text = ~annotation,\n    frame = ~seq,\n    x = 0.1,\n    y = 0.025,\n    textfont = list(size = 20)\n  ) |&gt;\n  layout(\n    showlegend = F\n  )\n\n\n\n\nFigure 2: Animated Bayesian Updating"
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html#on-priors",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html#on-priors",
    "title": "Garden of Forking paths part 2",
    "section": "On priors",
    "text": "On priors\n\nThe fact that statistical inference uses mathematics does not imply that there is only one reasonable or useful way to conduct an analysis."
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html#grid-approximation",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html#grid-approximation",
    "title": "Garden of Forking paths part 2",
    "section": "Grid approximation",
    "text": "Grid approximation\nOk, I’ll do one grid approximation for the hell of it.\n…\nGot distracted and went down a rabbit hole on the beta vs binomial distributions.\n\ntibble(\n  prob = seq(0.0001, 0.9999, length = 50), \n  prior_unstd = case_when(\n    prob &lt; 0.5 ~ 0,\n    .default = 1\n  ),\n  prior_std = prior_unstd/sum(prior_unstd),\n  likelihood_binom = dbinom(6, size = 9, prob = prob),\n  l_binom_std = likelihood_binom/sum(likelihood_binom),\n  likelihood_beta = dbeta(prob, 6, 9-6),\n  l_beta_std = likelihood_beta/sum(likelihood_beta)\n) |&gt; \n  ggplot(aes(prob))+\n    geom_point(aes(y = l_binom_std, color = \"binom\"))+\n    geom_point(aes(y = l_beta_std, color = \"beta\"))+\n    scale_color_bright()+\n    labs(\n      x = \"probability\",\n      color = \"distribution\",\n      y = NULL\n    )\n\n\n\n\nFigure 3: Comparing normalized densities for beta(6,3) and binom(6, 9, p)\n\n\n\n\nGlad I did this. I guess\n\ndbinom \\(\\propto P(O, S | p)\\)\ndbeta \\(\\propto P(p|O,S)\\)\n\nI guess I’d want to see dbinom plotted out with O on the x axis?\n\ntibble(\n  probability = seq(0.0001, 0.9999, length = 10)\n) |&gt; \n  rowwise() |&gt; \n  mutate(\n    densities = map(\n      probability,\n      ~tibble(obs = 0:9, \n              density = dbinom(obs, size = 9, prob = .x))\n    )\n  ) |&gt; \n  unnest(densities) -&gt;\n  binomial_densities \n\nbinomial_densities |&gt; \n  ggplot(aes(obs, density, color = probability))+\n    geom_point()+\n    geom_line(aes(group = probability)) +\n    geom_rect(\n      color = \"red\",\n      fill = NA,\n      xmin = 5.5,\n      xmax = 6.5,\n      ymin = 0,\n      ymax = 1\n    )+\n    scale_color_batlow()\n\n\n\n\nFigure 4: Binomial distributions of various successes out of 9 trials, for various p\n\n\n\n\nWhat we’re plotting out is what’s in the red box, flipped on its side.\n\nbinomial_densities |&gt; \n  filter(obs == 6) |&gt; \n  ggplot(aes(probability, density))+\n    geom_line()+\n    geom_point(aes(color = probability))+\n    scale_color_batlow()\n\n\n\n\nFigure 5: Normalized binomial density for 6 successes out of 9 trials for various p."
  },
  {
    "objectID": "posts/2023-05-10_03-forking-paths-2/index.html#update",
    "href": "posts/2023-05-10_03-forking-paths-2/index.html#update",
    "title": "Garden of Forking paths part 2",
    "section": "Update!",
    "text": "Update!\nThanks TJ!\n\n\ni forgot how i know this but they are the same if you plug in likelihood_beta = dbeta(prob, 1 + 6, 1 + 9-6),\n\n— tj mahr 🍍🍕 (@tjmahr) May 10, 2023\n\n\n\ntibble(\n  prob = seq(0.0001, 0.9999, length = 50), \n  prior_unstd = case_when(\n    prob &lt; 0.5 ~ 0,\n    .default = 1\n  ),\n  prior_std = prior_unstd/sum(prior_unstd),\n  likelihood_binom = dbinom(6, size = 9, prob = prob),\n  l_binom_std = likelihood_binom/sum(likelihood_binom),\n  likelihood_beta = dbeta(prob, (6+1), (9-6)+1),\n  l_beta_std = likelihood_beta/sum(likelihood_beta)\n) |&gt; \n  ggplot(aes(prob))+\n    geom_point(aes(y = l_binom_std, color = \"binom\"))+\n    geom_point(aes(y = l_beta_std, color = \"beta\"))+\n    scale_color_bright()+\n    labs(\n      x = \"probability\",\n      color = \"distribution\",\n      y = NULL\n    )\n\n\n\n\nFigure 6: Comparing normalized densities for beta(6+1,3+1) and binom(6, 9, p)"
  },
  {
    "objectID": "posts/2023-05-09_02-small-large-worlds/index.html",
    "href": "posts/2023-05-09_02-small-large-worlds/index.html",
    "title": "02 Small Worlds and Large Worlds",
    "section": "",
    "text": "listening\nIn the analogy, models are “Small”, self-contained worlds."
  },
  {
    "objectID": "posts/2023-05-09_02-small-large-worlds/index.html#garden-of-forking-paths.",
    "href": "posts/2023-05-09_02-small-large-worlds/index.html#garden-of-forking-paths.",
    "title": "02 Small Worlds and Large Worlds",
    "section": "Garden of forking paths.",
    "text": "Garden of forking paths.\nI was thinking of working out the probabilities by doing random sampling…\n\nlibrary(tidyverse)\nlibrary(gt)\nlibrary(patchwork)\nlibrary(here)\nsource(here(\"_defaults.R\"))\n\nGenerating the marble dataframe\n\ntibble(\n  blue_marbs = 0:4,\n  white_marbs = 4 - blue_marbs\n) |&gt; \n  rowwise() |&gt; \n  mutate(\n    marbles = list(c(rep(\"blue\", blue_marbs), rep(\"white\", white_marbs)))\n  ) -&gt; \n  marbles\n\n\nmarbles |&gt; \n  gt()\n\n\n\n\n\n\n  \n    \n    \n      blue_marbs\n      white_marbs\n      marbles\n    \n  \n  \n    0\n4\nwhite, white, white, white\n    1\n3\nblue, white, white, white\n    2\n2\nblue, blue, white, white\n    3\n1\nblue, blue, blue, white\n    4\n0\nblue, blue, blue, blue\n  \n  \n  \n\nTable 1:  The marble sampling distributions \n\n\n\nIn retrospect, I’m glad I did this, because I thought we were sampling without replacement.\nHere’s a function that will repeatedly sample from a set of marbles, and compare the result to a reference group.\n\nsampling_df &lt;- function(marbles, n = 1000, size = 3, pattern = c(\"blue\", \"white\", \"blue\")){\n1  sampling_tibble &lt;- tibble(samp = 1:n)\n  sampling_tibble |&gt; \n    mutate(\n2      chosen = map(samp, ~sample(marbles, size = 3, replace = T)),\n3      match = map_lgl(chosen, ~all(.x == pattern))\n    ) |&gt; \n4    summarise(prop_match = mean(match))-&gt;\n    sampling_tibble\n  return(sampling_tibble)\n}\n\n\n1\n\nI’ll capture everything within a tibble.\n\n2\n\nRowwise, sample from marbles with replacement.\n\n3\n\nReturn T or F if the sequence matches the pattern exactly.\n\n4\n\nThe mean() of the T, F column to get the proportion that match.\n\n\n\n\n\nsampling_df(\n  marbles = marbles$marbles[[4]],\n  n = 5000\n) \n\n# A tibble: 1 × 1\n  prop_match\n       &lt;dbl&gt;\n1      0.140\n\n\n\nmarbles |&gt; \n ungroup() |&gt; \n  mutate(\n    prob = map(marbles, ~sampling_df(.x, n = 10000))\n  ) |&gt; \n  unnest(prob) |&gt; \n  mutate(norm_probs = prop_match/sum(prop_match))-&gt;\n  marble_probs\n\n\nmarble_probs |&gt; \n  ggplot(aes(blue_marbs, norm_probs))+\n    geom_col(fill = \"steelblue4\")+\n    labs(\n      title = \"blue, white, blue\",\n      x = \"# of blue marbles\",\n      y = \"probability\"\n    ) + \n  ylim(0,1)-&gt;probs1\nprobs1\n\n\n\n\nFigure 1: Probability of each composition of marbles"
  },
  {
    "objectID": "posts/2023-05-09_02-small-large-worlds/index.html#updating-probabilities",
    "href": "posts/2023-05-09_02-small-large-worlds/index.html#updating-probabilities",
    "title": "02 Small Worlds and Large Worlds",
    "section": "Updating probabilities",
    "text": "Updating probabilities\nWhat if we draw one more blue\n\nmarble_probs |&gt; \n  mutate(new_obs_prob = blue_marbs / sum(blue_marbs),\n         posterior_prob = norm_probs * new_obs_prob,\n         posterior_norm = posterior_prob/sum(posterior_prob))-&gt;\n  marble_probs\n\n\nmarble_probs |&gt; \n  ggplot(aes(blue_marbs, posterior_norm))+\n    geom_col(fill = \"steelblue4\")+\n    ylim(0,1)+\n      labs(\n      title = \"probability update after blue\",\n      x = \"# of blue marbles\",\n      y = \"probability\"\n    ) -&gt;\n  probs2\n\nprobs1 | probs2\n\n\n\n\nFigure 2: Bayesian update"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Rethinking Workthrough Blog",
    "section": "",
    "text": "Garden of Forking paths part 2\n\n\n\n\n\n\n\n\n\n\n\n\nMay 10, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\n01 Golem of Prague Chapter\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\nSetup\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\n  \n\n\n\n\n02 Small Worlds and Large Worlds\n\n\n\n\n\n\n\n\n\n\n\n\nMay 9, 2023\n\n\nJosef Fruehwald\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is a blog to document my progress in working through Richard McElreath’s Statistical Rethinking: A Bayesian Course with Examples in R and Stan, which I’ll be supplementing with Solomon Kurz’ bookdown project, Statistical Rethinking with brms, ggplot2, and the tidyverse."
  }
]