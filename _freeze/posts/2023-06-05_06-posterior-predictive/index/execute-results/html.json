{
  "hash": "773cd64a09bca9c29f6d34ffbefb59e9",
  "result": {
    "markdown": "---\ntitle: \"Predictive Distributions\"\norder: 07\ndate: 2023-06-05\n---\n\n\n::: callout-note\n## Listening\n\n<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/51zSWEFaShJCDeeb3tJdQX?utm_source=generator\" width=\"100%\" height=\"152\" frameBorder=\"0\" allowfullscreen allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\" loading=\"lazy\">\n\n</iframe>\n:::\n\nOne last post to work through different predictive distributions given 6W and 3W.\n\n-   The prior predictive distribution.\n\n-   The maximum likelihood.\n\n-   the posterior predictive distribution.\n\n## Loading\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggdist)\nlibrary(here)\nlibrary(ggblend)\n\nsource(here(\"_defaults.R\"))\n```\n:::\n\n\n## Prior predictive\n\nThe prior was a Uniform distribution between 0 and 1, or $\\mathcal{U}(0,1)$. The outcome will also be uniform, but I'll go through all the steps for completeness.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  p = runif(1e4)\n) ->\n  prior_samp\n```\n:::\n\n\nI'll make use of vectorization of `rbinom()` to generate possible samples with probabilities in `prior_samp$p`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(2023)\nprior_samp |> \n  mutate(\n    pred_binom = rbinom(\n      n(), \n      size = 9, \n      prob = p\n    )\n  ) |> \n  count(pred_binom) |> # <1>\n  mutate(prob = n/sum(n)) ->\n  prior_pred\n```\n:::\n\n\n1.  I'm going straight from generated samples to summarising for the distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprior_pred |> \n  ggplot(aes(pred_binom, prob))+\n    geom_col()+\n    scale_x_continuous(\n      name = \"predicted W\",\n      breaks = seq(1, 9, by = 2)\n    )+\n    theme_no_y() # <1>\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-4-1.png){width=576}\n:::\n:::\n\n\n1.  I've moved `theme_no_y()` into `_defaults.R` which I source at the top.\n\n## Maximum Likelihood\n\nThe maximum likelihood probability of W is $\\frac{6}{9}=0.6\\overline{6}$. We can get predicted values for that probability from binomial distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  pred_binom = 0:9,\n  dens = dbinom(\n    pred_binom, \n    size = 9, \n    prob = 6/9\n  ),\n  prob = dens\n) -> \n  ml_pred\n\nml_pred |> \n  ggplot(aes(pred_binom, prob))+\n    geom_col()+\n    scale_x_continuous(\n      name = \"predicted W\",\n      breaks = seq(1, 9, by = 2)\n    )+\n    theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=576}\n:::\n:::\n\n\n## Posterior Prediction\n\nFor the posterior prediction, first we sample probabilities from the beta distribution\n\n$$\np \\sim \\text{Beta}(W+1, L+1)\n$$\n\n(a.k.a. `dbeta()`)\n\nThen for each $p$, we generate predictions from the binomial distribution.\n\n$$\nY|p \\sim \\text{Bin}(9,p)\n$$\n\nThis chapter has been doing grid sampling, but I'll just use the `rbeta()` function for simplicity.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntibble(\n  p = rbeta(1e4, 6+1, 3+1)\n) ->\n  posterior_samp\n```\n:::\n\n\nThen, it's the same operation as the prior predictive distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_samp |> \n   mutate(\n    pred_binom = rbinom(\n      n(), \n      size = 9, \n      prob = p\n    )\n  ) |> \n  count(pred_binom) |> \n  mutate(prob = n/sum(n)) ->\n  posterior_pred\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_pred |> \n  ggplot(aes(pred_binom, prob))+\n    geom_col() +\n    scale_x_continuous(\n      name = \"predicted W\",\n      breaks = seq(1, 9, by = 2)\n    ) +\n    theme_no_y()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=576}\n:::\n:::\n\n\n## Comparisons\n\nNow, I want to compare the posterior predictive distribution to the maximum likelihood and the prior. This is one concept I had, which has the prior and the ML values as thinner bars within the posterior predictive bars.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_pred |> \n  ggplot(aes(pred_binom, prob))+\n    geom_col()+\n    geom_segment(\n      data = ml_pred,\n      aes(\n        x = pred_binom-0.1,\n        xend = pred_binom-0.1,\n        yend = 0,\n        color = \"maximum likelihood\"\n      ),\n      linewidth = 2\n    )+\n    geom_segment(\n      data = prior_pred,\n      aes(\n        x = pred_binom+0.1,\n        xend = pred_binom+0.1,\n        yend = 0,\n        color = \"prior\"\n      ),\n      linewidth = 2\n    )+  \n    scale_x_continuous(\n      breaks = seq(1, 9, length = 2)\n    )+\n    labs(\n      color = NULL,\n      x = \"predicted W\"\n    )+\n    theme_no_y()+\n    theme(\n      legend.position = \"top\"\n    )\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=576}\n:::\n:::\n\n\nOverplotting them is also a possibility, and a good occasion to test out `{ggblend}`. I had some issues getting this to work with the available graphic devices & quarto.\n\n\n::: {.cell}\n\n````{.cell-code}\n```{{r}}\n#| dev: \"png\"\n#| dev-args:\n#|   - type: \"cairo\"\nbind_rows(\n  posterior_pred |> \n    mutate(pred = \"posterior\"),\n  ml_pred |> \n    mutate(pred = \"maximum likelihood\"),\n  prior_pred |> \n    mutate(pred = \"prior\")\n) |> \n  ggplot(aes(pred_binom, prob, fill = pred))+\n    geom_area(position = \"identity\", alpha = 0.5) * \n      (blend(\"lighten\") + blend(\"darken\")) +\n    scale_x_continuous(\n      name = \"predicted W\",\n      breaks = seq(1, 9, by = 2)\n    )+\n    theme_no_y()+\n    theme(\n      legend.position = \"top\"\n    )\n```\n````\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-10-1.png){width=576}\n:::\n:::\n\n\n## Visualizing the posterior prediction process\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_samp |> \n  slice(1:4) |> \n  mutate(\n    pred_binom = rbinom(\n      n(), \n      size = 9, \n      prob = p\n    )\n  ) |> \n  arrange(\n    p\n  ) ->\n  example_samp\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexample_samp |> \n  mutate(\n    dens = dbeta(p, 6+1, 3+1),\n    n = row_number()\n  )->\n  example_samp\n\ntibble(\n  p = seq(0, 1, length = 100),\n  dens = dbeta(p, 6+1, 3+1)\n) |> \n  ggplot(aes(p, dens))+\n    geom_area(fill = \"grey\") +\n    geom_segment(\n      data = example_samp,\n      aes(\n        xend = p,\n        yend = 0,\n        color = factor(n)\n      ),\n      linewidth = 1.5,\n      lineend = \"round\",\n      show.legend = F\n    )+\n    theme_no_y()+\n    labs(\n      title = \"Posterior\"\n    )->\n  posterior_plot\n```\n:::\n\n\nThis involved messing around with [`{rlang}` data masking](https://rlang.r-lib.org/reference/topic-data-mask-ambiguity.html) that I still don't quite follow. Both the `p` and `pred` arguments had to be (just once!) prefixed with `!!`, but not `n`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample_plot_fun <- function(p, pred, n){\n  this_scale <- as.vector(khroma::color(\"bright\")(4))\n  tibble(\n    ws = 0:9,\n    dens = dbinom(ws, size = 9, prob = !!p)\n  ) |> \n    ggplot(aes(ws, dens))+\n      geom_col(\n        aes(fill = ws == !!pred)\n      )+\n      scale_fill_manual(\n        values = c(\"grey\", this_scale[n]),\n        guide = \"none\"\n      ) +\n      scale_x_continuous(\n        breaks = seq(1,9, by = 2)\n      )+\n      labs(\n        x = \"prediction\",\n        title = str_glue(\"p = {round(p, digits = 2)}\")\n      ) +\n      theme_no_y()+\n      theme(\n        plot.title = element_text(size = 10)\n      )\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nexample_samp |> \n  rowwise() |> \n  mutate(\n    plot = list(\n      sample_plot_fun(p, pred_binom, n)\n    )\n  )->\n  samp_plots\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(patchwork)\n```\n:::\n\n\nGoing to use some patchwork and `purr::reduce()` fanciness.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_plot/\n(samp_plots |> \n  ungroup() |> \n  pull(plot) |> \n  reduce(.f = `+`) +\n  plot_layout(nrow = 1))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-16-1.png){width=576}\n:::\n:::\n\n\nPretty pleased with this!\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}