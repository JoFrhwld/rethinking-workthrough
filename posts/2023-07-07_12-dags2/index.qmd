---
title: "DAGs part 2"
date: 2023-07-07
order: 13
twitter-card: true
open-graph: true
---

::: callout-note
## Listening

<iframe style="border-radius:12px" src="https://open.spotify.com/embed/track/1TfqLAPs4K3s2rJMoCokcS?utm_source=generator" width="100%" height="152" frameBorder="0" allowfullscreen allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy">

</iframe>
:::

For part 2, I'm going to try working through this step by step like he does in the book.

## Setup

```{r}
#| code-fold: true
#| code-summary: "loading libraries and defaults"

library(tidyverse)
library(tidybayes)
library(brms)
library(gt)
library(gtsummary)
library(patchwork)
library(ggblend)
library(marginaleffects)
library(dagitty)
library(ggdag)
library(ggrepel)

source(here::here("_defaults.R"))
```

```{r}
set.seed(2023-7-7)
```

## The data

We're looking at the `rethinking::milk` data

```{r}
data(milk, package = "rethinking")
```

Let's try some summaries. For the categorical data, I'm going to do my own custom summary, but for the numeric columns I'll just use `gtsummary::tbl_summary().`

As it turns out, just like usual when I start trying to finesse things, the code got a little intense.

```{r}
#| label: tbl-cat
#| tbl-cap: "Summary of categorical variables"
#| code-fold: true
#| code-summary: "Categorical summary"
milk |> 
  select(
    where(
      ~!is.numeric(.x)
    )
  ) |> 
  pivot_longer(
    cols = everything(),
    names_to = "var",
    values_to = "value"
  ) |> 
  summarise(
    .by = var,
    total_groups = n_distinct(value),
    most_common = fct_count(
      factor(value),
      sort = T,
      prop = T
      ) |> 
      slice(1)
  ) |> 
  unnest(most_common) |> 
  gt() |> 
     cols_label(
       var = "Variable",
       total_groups = "Total Groups",
       f = "Most common",
       n = "Number of most common",
       p = "Proportion of most common"
     ) |> 
  fmt_number(
    columns = p,
    decimals = 2
  )
```

Comparing the code I wrote for the categorical variables to how straightforward `tbl_summary()` is kind of illustrates how useful these out-of-the-box tools can be.

```{r}
#| label: tbl-cont
#| tbl-cap: "Summary of continuous variables"
milk |> 
  select(
    where(is.numeric)
  ) |> 
  tbl_summary()
```

## The initial model

Ok, we're going to model the kilocalories per gram of milk as the outcome, trying to explore whether or not the neocortex percentage is related.

```{r}
#| label: fig-dataplot
#| crop: true
#| fig-cap: "Neorcortex percentage and kcal per gram of milk"
#| code-fold: true
#| code-summary: "plotting code"
milk |> 
  drop_na() |> 
  ggplot(
    aes(
      neocortex.perc, 
      kcal.per.g,
      color = clade,
      fill = clade
    )
  )+
    geom_point(
      key_glyph = "rect"
    )+
    geom_text_repel(
      aes(label = species), 
      size = 3,
      show.legend = F
    )+
    theme(
      aspect.ratio = 1
    )
```

### Preparing the data

I won't look ahead and drop NAs when I standardize to save some space. Looks like we're logging the body mass. I'll just check that distribution real quick.

```{r}
#| label: fig-mass
#| fig-cap: "Distribution of mass on a linear vs log scale"
#| fig-width: 10
#| fig-height: 4
milk |> 
  ggplot(aes(mass))+
    stat_slab()+
    geom_rug()+
    labs(
      title = "linear scale"
    )+
    theme_no_y()->
  mass_linear

milk |> 
  ggplot(aes(mass))+
    stat_slab()+
    geom_rug()+
    scale_x_log10()+
    labs(
      title = "log scale"
    )+
    theme_no_y()->
  mass_log

mass_linear + mass_log
```

Yup! Looks like we should log it!

```{r}
milk |> 
  drop_na() |> 
  mutate(
    kcal_z = (kcal.per.g-mean(kcal.per.g))/sd(kcal.per.g),
    neoc_z = (neocortex.perc-mean(neocortex.perc))/sd(neocortex.perc),
    log_mass = log(mass),
    log_mass_z = (log_mass - mean(log_mass))/sd(log_mass)
  ) ->
  milk_to_mod
```

### Fitting the model

I'll fit models with both the weak priors and the stronger priors. I'm still needing to check what everything is called with `get_prior()` before I can confidently set anything.

```{r}
get_prior(
  kcal_z ~ neoc_z,
  data = milk_to_mod
)
```

Ok, should do the trick.

```{r}
brm(
  kcal_z ~ neoc_z,
  data = milk_to_mod,
  prior = c(
    prior(normal(0,1), class = b),
    prior(normal(0,1), class = Intercept),
    prior(exponential(1), class = sigma) 
  ),
  sample_prior = T,
  file = "neoc_model_weak.rds",
  cores = 4,
  backend = "cmdstanr"
)->
  neoc_model_weak
```

```{r}
brm(
  kcal_z ~ neoc_z,
  data = milk_to_mod,
  prior = c(
    prior(normal(0,0.5), class = b),
    prior(normal(0,0.2), class = Intercept),
    prior(exponential(1), class = sigma) 
  ),
  sample_prior = T,
  file = "neoc_model_strong.rds",
  cores = 4,
  backend = "cmdstanr"
)->
  neoc_model_strong
```

### Prior predictive plots

You can set an option in `brm` to only sample the priors for something like this, but instead I just fit whole models to save time. This'll need to be a bit "manual", cause I don't think `marginaleffects::predictions()` has an option to get prior predictions.

```{r}
prior_draws(neoc_model_weak) |> 
  mutate(
    draw = row_number(),
      priors = "weak"
  ) |> 
  rowwise() |> 
  mutate(
    pred = list(tibble(
      neoc_z = seq(-2, 2, length = 50),
      kcal_z = Intercept + (neoc_z * b)
    ))
  ) ->
  weak_prior_predictive
```

And then the same thing for the strong priors model.

```{r}
#| code-fold: true
#| code-summary: "same as above"
prior_draws(neoc_model_strong) |> 
  mutate(
    draw = row_number(),
      priors = "strong"
  ) |> 
  rowwise() |> 
  mutate(
    pred = list(tibble(
      neoc_z = seq(-2, 2, length = 50),
      kcal_z = Intercept + (neoc_z * b)
    ))
  ) ->
  strong_prior_predictive
```

I'll just sample 50 fitted lines for each model.

```{r}
#| label: fig-prior-pred
#| crop: true
#| fig-cap: "prior predictive distributions"
bind_rows(
  weak_prior_predictive,
  strong_prior_predictive
) |> 
  group_by(priors) |> 
  sample_n(50) |> 
  unnest(pred) |> 
  ggplot(aes(neoc_z, kcal_z)) +
    geom_line(
      aes(group = draw)
    )+
    facet_wrap(~priors)+
    theme(
      aspect.ratio = 1
    )
```

So, the "weaker" priors are "silly" (as McElreath puts it) because for some `noec_z` values, it's predicting `kcal_z` values as extreme as 6. And because I standardized the outcome, that's saying some `kcal_z` values are up to 6 standard deviations from the average. R actually craps out trying to give the cumulative probability!

```{r}
pnorm(6, mean = 0, sd = 1)
```

### The Posteriors

Lemme compare the posterior parameter estimates for the two models.

```{r}
neoc_model_weak |> 
  gather_draws(
    `b_.*`,
    regex = T
  ) |> 
  mutate(priors = "weak") ->
  weak_betas

neoc_model_strong |> 
  gather_draws(
    `b_.*`,
    regex = T
  ) |> 
  mutate(priors = "strong") -> 
  strong_betas
```

```{r}
#| fig-width: 8
#| fig-height: 4
#| label: fig-posterior-comp
#| fig-cap: "parameter estimates by model"
bind_rows(
  weak_betas,
  strong_betas
) |> 
  ggplot(aes(.value, priors))+
    stat_halfeye()+
    facet_wrap(~.variable)
```

The posterior distribution for the Intercept might be notably different, but they're still pretty comparable.

Let's see the predicted values.

```{r}
#| crop: true
#| label: fig-neoc-pred
#| fig-cap: "Posterior estimates of kcal_z"
#| code-fold: true
#| code-summary: "plotting code"
predictions(
  neoc_model_strong,
  newdata = datagrid(
    neoc_z = seq(-2, 2, length = 50)
  )
) |> 
  posterior_draws() ->
  neoc_fit1

neoc_fit1 |> 
  ggplot(aes(neoc_z, draw))+
    stat_lineribbon(
      .width = c(
        0.89,
        0.7,
        0.5
      )
    )+
    scale_fill_brewer()+
    labs(
      title = "kcal ~ neocortex",
      y = "kcal_z"
    )+
    theme(
      aspect.ratio = 1
    )
```

## More Models

Ok, we're also going to fit modes for

-   kcal_z \~ log_mass_z

-   kcal_z \~ neoc_z + log_mass_z

```{r}
brm(
  kcal_z ~ log_mass_z,
  data = milk_to_mod,
  prior = c(
    prior(normal(0,0.5), class = b),
    prior(normal(0,0.2), class = Intercept),
    prior(exponential(1), class = sigma) 
  ),
  sample_prior = T,
  file = "mass_model.rds",
  cores = 4,
  backend = "cmdstanr"
)->
  mass_model
```

```{r}
brm(
  kcal_z ~ neoc_z + log_mass_z,
  data = milk_to_mod,
  prior = c(
    prior(normal(0,0.5), class = b),
    prior(normal(0,0.2), class = Intercept),
    prior(exponential(1), class = sigma) 
  ),
  sample_prior = T,
  file = "neoc_mass_model.rds",
  cores = 4,
  backend = "cmdstanr"
)->
  neoc_mass_model
```

We can compare the parameters from each with some reused code from above!

```{r}
#| code-fold: true
#| code-summary: "posterior getting"
mass_model |> 
  gather_draws(
    `b_.*`,
    regex = T
  ) |> 
  mutate(model = "~mass") -> 
  mass_betas

neoc_mass_model |> 
  gather_draws(
    `b_.*`,
    regex = T
  ) |> 
  mutate(model = "~neoc+mass") -> 
  neoc_mass_betas

strong_betas |> 
  mutate(model = "~neoc") ->
  neoc_betas
```

```{r}
#| label: fig-all-param
#| fig-cap: "Comparison of parameters across models"
#| crop: true
#| fig-width: 10
#| fig-height: 4
#| code-fold: true
#| code-summary: "plotting code"
bind_rows(
  neoc_betas,
  mass_betas,
  neoc_mass_betas
) |> 
  ggplot(aes(.value, model))+
    stat_halfeye(
      aes(fill = after_stat(x >= 0)),
      show.legend = F
    )+
    facet_wrap(~.variable)+
    theme(
      aspect.ratio = 0.75
    )
```

So, including *both* predictors in the model amplified the effect for both of them. We can get the fitted values now

```{r}
#| label: fig-noec-comp
#| fig-cap: "comparison of predicted values across neocortex percentage"
#| crop: true
#| code-fold: true

predictions(
  neoc_mass_model,
  newdata = datagrid(
    neoc_z = seq(-2, 2, length = 50),
    log_mass_z = 0
  )
) |> 
  posterior_draws() |>  
  mutate(model = "~neoc + mass")-> 
  neoc_fit2

neoc_fit1 |> 
  mutate(model = "~neoc")->
  neoc_fit1

bind_rows(
  neoc_fit1,
  neoc_fit2
) |> 
  ggplot(aes(neoc_z, draw))+
    stat_lineribbon(
      .width = c(0.89,0.7, 0.5),
      color = NA
    )  +
    scale_fill_brewer()+
   labs(
     y = "kcal_z",
     subtitle = "log_mass_z = 0"
   )+
   facet_wrap(~model)+
   theme(
     aspect.ratio = 1
   )
```

```{r}
#| label: fig-mass-comp
#| fig-cap: "comparison of predicted values across bodymass"
#| crop: true
#| code-fold: true
predictions(
  mass_model,
  newdata = datagrid(
    log_mass_z = seq(-2, 2, length = 50),
    neoc_z = 0
  )
) |> 
  posterior_draws() |> 
  mutate(model = "~mass")->
  mass_fit1

predictions(
  neoc_mass_model,
  newdata = datagrid(
    log_mass_z = seq(-2, 2, length = 50),
    neoc_z = 0
  )
) |> 
  posterior_draws() |> 
  mutate(model = "~neoc + mass")->
  mass_fit2

bind_rows(
  mass_fit1,
  mass_fit2
) |> 
  ggplot(aes(log_mass_z, draw))+
    stat_lineribbon(
      .width = c(0.89,0.7, 0.5),
      color = NA
    )  +
    scale_fill_brewer()+
   labs(
     y = "kcal_z",
     subtitle = "neoc_z = 0"
   )+
   facet_wrap(~model)+
   theme(
     aspect.ratio = 1
   )
```

## Why?

Each predictor is correlated with the outcome, and also (strongly) correlated with each other.

```{r}
#| label: fig-pairs
#| fig-cap: "Relationship between the three variables"
#| fig-width: 5
#| fig-height: 5
#| code-fold: true
#| crop: true
milk_to_mod |> 
  ggplot(aes(log_mass_z, kcal_z))+
    geom_point()+
    stat_smooth(
      method = 'lm',
      se = F,
      color = ptol_blue
    )+
    scale_x_continuous(position = "top")->
  mass_kcal

milk_to_mod |> 
  ggplot(aes(neoc_z, kcal_z))+
    geom_point()+
    stat_smooth(
      method = 'lm',
      se = F,
      color = ptol_blue
    )+
    scale_x_continuous(position = "top")+
    scale_y_continuous(position = "right")+
  theme(
    aspect.ratio = 1
  )->
  neoc_kcal

milk_to_mod |> 
  ggplot(aes(log_mass_z, neoc_z))+
    geom_point()+
    stat_smooth(
      method = 'lm',
      se = F,
      color = ptol_blue
    )+
  theme(
    aspect.ratio = 1
  )->
  mass_neoc

layout <- "
AB
C#
"

mass_kcal + neoc_kcal + mass_neoc + plot_layout(design = layout)
```

### Isn't this collinearity?

So, on this point, I'm not completely sure how I should feel about the model with both body mass and neocortex percentage, since it looks like "collinearity" which is supposed to be ðŸ‘» spooky ðŸ‘». In the book, he gives three possible DAGs, so I'll see what the "adjustment sets" are like for each.

```{r}
dagify(
  kcal ~ mass,
  kcal ~ neoc,
  neoc ~ mass
) |> 
  adjustmentSets(
    outcome = "kcal",
    exposure = "neoc",
    effect = "direct"
    )
```

```{r}
dagify(
  kcal ~ mass,
  kcal ~ neoc,
  # flipping this
  mass ~ neoc
) |> 
  adjustmentSets(
    outcome = "kcal",
    exposure = "neoc",
    effect = "direct"
  )
```

```{r}
dagify(
  kcal ~ mass,
  kcal ~ neoc,
  mass ~ UNK,
  neoc ~ UNK,
  latent = "UNK"
) |> 
  adjustmentSets(
    outcome = "kcal",
    exposure = "neoc",
    effect = "direct"
  ) 
```

Well, they all say to get the direct effect of neocortex percentage on kcal per gram, you need to include mass... Which I can be cool with, I just need to figure out how we're thinking about collinearity now! Maybe the paper [Collinearity isn't a disease that needs curing](Collinearity isn't a disease that needs curing) is a place to start!

